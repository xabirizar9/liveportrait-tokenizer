{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xabieririzar/liveportrait-tokenizer/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "from random import seed\n",
    "import pickle\n",
    "import yaml\n",
    "import imageio\n",
    "from copy import deepcopy\n",
    "\n",
    "from src.modules.vqvae import VQVae\n",
    "from src.modules.fsq_vqvae import FSQVAE\n",
    "from train_tokenizer import VQVAEModule\n",
    "from src.dataset import Dataset\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.tokenizer_utils import load_fsq_vae, prepare_features, process_reconstruction, repackage_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dir = Path(\"dataset/pickles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_fsq, rest_feats = load_fsq_vae(Path(\"outputs/modified_rest_fsq_D4/checkpoints/checkpoint_epoch=319.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_scale_fsq, rot_scale_feats = load_fsq_vae(Path(\"outputs/modified_rot_scale_D4/checkpoints/checkpoint_epoch=339.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fsq, exp_feats = load_fsq_vae(Path(\"outputs/modified_rest_vel_reg_fsq_D4/checkpoints/checkpoint_epoch=459.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lip_fsq, lip_feats = load_fsq_vae(Path(\"outputs/modified_lips_vel_reg_fsq_D4/checkpoints/checkpoint_epoch=229.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(\"dataset\", split=\"eval\", val_split=0.1, seed=2, compute_stats=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(0, 20):\n",
    "#     target_ids = [\"dataset/pickles/JRG5gXNZbgQ_3.pkl\"]#, \"dataset/pickles/droRkoEh8iE_18.pkl\", \"dataset/pickles/WQvT1_tQDhg_22.pkl\"]\n",
    "\n",
    "#     counter = 0\n",
    "\n",
    "#     ds = Dataset(\"dataset\", split=\"eval\", val_split=0.1, seed=j, compute_stats=False)\n",
    "#     # find_id = f\"dataset/pickles/{test_id}.pkl\"\n",
    "\n",
    "#     for i, item in enumerate(ds):\n",
    "#         if item['metadata']['pickle_path'] in target_ids:\n",
    "#             counter += 1\n",
    "#             print(j, i)\n",
    "        \n",
    "#         if counter == 2:\n",
    "#             exit()\n",
    "#     counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare ds item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1746 guy video\n",
    "# 134 girl video seed 2\n",
    "# 122 seed 1\n",
    "\n",
    "sample = ds[134] \n",
    "\n",
    "pickle_path = sample['metadata']['pickle_path']\n",
    "vid_id = pickle_path.split(\"/\")[-1].split(\".\")[0]\n",
    "vid_path = f\"dataset/train/{vid_id}.mp4\"\n",
    "\n",
    "# Read the first frame from the video and display it\n",
    "frame = imageio.get_reader(vid_path).get_data(0)\n",
    "plt.imshow(frame)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_features, exp_dims = prepare_features(sample, exp_feats, only_lips=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_features, rest_dims = prepare_features(sample, rest_feats, only_lips=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_scale_features, r_scale_dims = prepare_features(sample, rot_scale_feats, only_lips=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_lip, lip_dims = prepare_features(sample, lip_feats, only_lips=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stats\n",
    "stats = pickle.load(open(\"dataset/stats_all.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send stats to GPU\n",
    "for key in stats['mean']:\n",
    "    stats['mean'][key] = stats['mean'][key].to(\"cuda\")\n",
    "    stats['std'][key] = stats['std'][key].to(\"cuda\")\n",
    "std = stats['std']\n",
    "mean = stats['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    reconstr_rest = rest_fsq(rest_features)\n",
    "    reconstr_r_scale = rot_scale_fsq(r_scale_features)\n",
    "    reconstr_exp_rest = exp_fsq(exp_features)\n",
    "    reconstr_lip = lip_fsq(feats_lip)\n",
    "    \n",
    "    # Remove velocity components\n",
    "    reconstr_exp = torch.cat([reconstr_exp_rest[..., :48], reconstr_lip[..., :15]], dim=-1)\n",
    "    exp_dims['exp'] = 63\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     rest_indices = rest_fsq.encode(rest_features)\n",
    "#     r_scale_indices = rot_scale_fsq.encode(r_scale_features)\n",
    "#     exp_indices = exp_fsq.encode(exp_features)\n",
    "#     lip_indices = lip_fsq.encode(feats_lip)\n",
    "\n",
    "# print(f\"First 10 codes: {rest_indices[:, :10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     rest_codes = rest_fsq.quantizer.indices_to_codes(rest_indices)\n",
    "#     r_scale_codes = rot_scale_fsq.quantizer.indices_to_codes(r_scale_indices)\n",
    "#     exp_codes = exp_fsq.quantizer.indices_to_codes(exp_indices)\n",
    "#     lip_codes = lip_fsq.quantizer.indices_to_codes(lip_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     rest_codes = rest_fsq.preprocess(rest_codes)\n",
    "#     r_scale_codes = rot_scale_fsq.preprocess(r_scale_codes)\n",
    "#     exp_codes = exp_fsq.preprocess(exp_codes)\n",
    "#     lip_codes = lip_fsq.preprocess(lip_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     reconstr_rest = rest_fsq.decoder(rest_codes)\n",
    "#     reconstr_r_scale = rot_scale_fsq.decoder(r_scale_codes)\n",
    "#     reconstr_exp_rest = exp_fsq.decoder(exp_codes)\n",
    "#     reconstr_lip = lip_fsq.decoder(lip_codes)\n",
    "\n",
    "#     reconstr_rest = rest_fsq.postprocess(reconstr_rest)\n",
    "#     reconstr_r_scale = rot_scale_fsq.postprocess(reconstr_r_scale)\n",
    "#     reconstr_exp_rest = exp_fsq.postprocess(reconstr_exp_rest)\n",
    "#     reconstr_lip = lip_fsq.postprocess(reconstr_lip)\n",
    "\n",
    "#     reconstr_exp = torch.cat([reconstr_exp_rest[..., :45], reconstr_lip[..., :18]], dim=-1)\n",
    "#     exp_dims['exp'] = 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test encoding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    encodings = rest_fsq.encode(rest_features)\n",
    "    result = rest_fsq.decode(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_new_reconstr = process_reconstruction(rest_dims, reconstr_rest, False, std, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_scale_new_reconstr = process_reconstruction(r_scale_dims, reconstr_r_scale, False, std, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_new_reconstr = process_reconstruction(exp_dims, reconstr_exp, False, std, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reconstr = torch.zeros((*rest_new_reconstr.shape[:-1], 205))\n",
    "new_reconstr[..., :9] = r_scale_new_reconstr[..., :9]\n",
    "new_reconstr[..., 9:12] = rest_new_reconstr[..., :3]\n",
    "new_reconstr[..., 12:75] = exp_new_reconstr\n",
    "new_reconstr[..., 75:138] = rest_new_reconstr[..., 3:66]\n",
    "new_reconstr[..., 138:139] = rest_new_reconstr[..., 75:76]\n",
    "new_reconstr[..., 138:139] = r_scale_new_reconstr[..., 9:10]\n",
    "new_reconstr[..., 139:142] = rest_new_reconstr[..., 66:69]\n",
    "new_reconstr[..., 142:205] = rest_new_reconstr[..., 69:132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dims = {\n",
    "    'R': 9,\n",
    "    'c_eyes_lst': 2,\n",
    "    'c_lip_lst': 1,\n",
    "    'exp': 63,\n",
    "    'kp': 63,\n",
    "    'scale': 1,\n",
    "    't': 3,\n",
    "    'x_s': 63\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeros = torch.zeros(1, new_reconstr.shape[1], new_reconstr.shape[-1] + 18)\n",
    "# # full_exp = sample['exp'][:95].reshape(1, 95, -1).to('cuda')\n",
    "\n",
    "# cur_ind = 0\n",
    "# reconstr_ind = 0\n",
    "\n",
    "# for feat, indices in dims.items():\n",
    "#     print(f\"{feat}: {cur_ind}: {cur_ind + indices}\")\n",
    "#     if feat == 'exp':\n",
    "#         zeros[..., cur_ind: cur_ind + indices] = new_reconstr[..., reconstr_ind: reconstr_ind + indices] \n",
    "#         # zeros[..., cur_ind: cur_ind + indices] = full_exp[..., reconstr_ind: reconstr_ind + indices] \n",
    "#         zeros[..., cur_ind + indices: cur_ind + indices + 18] = reconst_lip * std[feat][:, 45:] + mean[feat][:, 45:]\n",
    "#         cur_ind += indices + 18\n",
    "        \n",
    "#         reconstr_ind += indices\n",
    "#     else:\n",
    "#         zeros[..., cur_ind: cur_ind + indices] = new_reconstr[..., reconstr_ind: reconstr_ind + indices]\n",
    "#         cur_ind += indices\n",
    "#         reconstr_ind += indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_feats = sample['exp'][:300].reshape(1, 300, -1).to('cuda')\n",
    "# zeros = torch.zeros_like(full_feats, device='cuda')\n",
    "# zeros[..., :45] = new_reconstr\n",
    "# zeros[..., 45:] = full_feats[..., 45:] * std['exp'][:, 45:] + mean['exp'][:, 45:]\n",
    "\n",
    "# new_reconstr = zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate reconstructed pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rest_feats = {}\n",
    "\n",
    "for key, value in rest_feats.items():\n",
    "    new_rest_feats[key] = value\n",
    "    new_rest_feats[key]['enabled'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = repackage_output(sample, new_reconstr, ds, dims=new_dims, feats_data=new_rest_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace reconstructed features with original ones for a specific range\n",
    "# feat = 'exp'\n",
    "\n",
    "# feat_range = (0, 16)\n",
    "\n",
    "# denormalized_sample = ds.denormalize_features(sample[feat], feat)\n",
    "\n",
    "# for i in range(output['n_frames']):\n",
    "#     output['motion'][i][feat][:, feat_range[0]:feat_range[1]] = denormalized_sample[i][:, feat_range[0]:feat_range[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = Path(pickle_path).stem\n",
    "new_path = pickle_dir / f\"{video_id}_reconstructed.pkl\"\n",
    "print(new_path)\n",
    "with open(new_path, \"wb\") as f:\n",
    "    pickle.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "vid = imageio.get_reader(f\"dataset/train/{video_id}.mp4\")\n",
    "frame = vid.get_data(0)\n",
    "\n",
    "# save frame\n",
    "imageio.imwrite(\"assets/examples/source/reconstructed.png\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference.py -d {new_path} -s assets/examples/source/reconstructed.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
